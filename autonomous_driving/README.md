# 量子化誤差と不均衡ラベルを学ぶモデル

こちらは、ラズベリーパイカーで自動走行について、不均一ラベルと、量子化について検証をしたものとなっています。


# 背景
既存のモデルでは、不均一なデータ量のモデルに対しマイナーなデータ数のモデルが、マジョリティークラスに分類されてしまうというものがあります。
例えば、コース左回りに対してデータを取った場合、まっすぐ＞左＞右となり、右の画像がまっすぐに分類されやすくなってしまいます。

![image](https://github.com/user-attachments/assets/3f486db8-d235-4a46-8117-15aa69e25bc9)


また、ラズベリーパイ上で自動走行モデルを実装する際は、モデルを軽量化(ここでは量子化)をする必要があり、それによって更なる精度劣化を引き起こします。


![image](https://github.com/user-attachments/assets/7957d0d0-33d5-4cc0-9697-1fab0ad74196)


そこで今回は、モデル大して誤分類しやすいラベルのコストを学ばせて、
自動運転の信頼性の向上を目指しました。

# 方法

使用するデータセットは、左, まっすぐ, 右の3クラスステアリング操作のデータセットです。使用しているコースはドーナッツ型で、それぞれのデータセット枚数は以下のようになっています。

```
Train データセットのクラスごとのデータ数:
クラス "left" のデータ数: 3242サンプル
クラス "right" のデータ数: 97サンプル
クラス "straight" のデータ数: 1068サンプル

Validation データセットのクラスごとのデータ数:
クラス "left" のデータ数: 219サンプル
クラス "right" のデータ数: 8サンプル
クラス "straight" のデータ数: 717サンプル

Test データセットのクラスごとのデータ数:
クラス "left" のデータ数: 370サンプル
クラス "right" のデータ数: 52サンプル
クラス "straight" のデータ数: 245サンプル
```
コース班時計周りにデータを取ったため、右のサンプルが不足しています。
これに対して私は、量子化認識学習モデルと、量子化と不均一ラベルに対する誤分類コストを同時に学ばせる、つまり右であるにもかかわらずまっすぐという
場所にコストを置き学習させて比較しました。各モデルは100エポック、オプティマイザーはSGD, lr=0.001, momentum = 0.9, nestrov = True, weigth_decay = 5e-4で学習させます。
