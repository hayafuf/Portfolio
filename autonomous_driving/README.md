# 量子化誤差と不均衡ラベルを学習するモデル

こちらは、ラズベリーパイカー上で自動走行に関する実験を行い、不均衡なラベル分布と量子化について検証したものです。


# 背景
既存のモデルでは、データの不均衡が原因で、少数派クラスのデータが多数派クラスに誤分類されやすいという課題があります。
例えば、コースの左回りデータを取得した場合、直進 > 左 > 右の順でデータ量が多くなるため、右方向の画像が直進に誤分類されやすくなります。
![image](https://github.com/user-attachments/assets/3f486db8-d235-4a46-8117-15aa69e25bc9)


また、ラズベリーパイ上で自動走行モデルを実装する際には、モデルの軽量化（ここでは量子化）が必須となります。しかし、量子化によって更なる精度劣化が生じる問題があります。

![image](https://github.com/user-attachments/assets/7957d0d0-33d5-4cc0-9697-1fab0ad74196)


そこで本検証では、モデルが誤分類しやすいラベルに対して学習コストを適応的に与え、不均衡データと量子化誤差の影響を低減し、自動運転モデルの信頼性向上を目指しました。

# 方法

コースを反時計回りに走行してデータ収集を行ったため、右方向のサンプルが著しく不足しています。
これに対して、本研究では次の2種類のモデルを比較しました。

量子化認識学習モデル

量子化と不均衡ラベル誤分類コストを同時に学習するモデル
（右方向を直進に誤分類しやすい場合にペナルティを与えるなど）

各モデルは100エポック、オプティマイザとしてSGD（学習率=0.001、momentum=0.9、Nesterov=True、weight_decay=5e-4）を使用して学習しました。
また、主張をより強固にするため、モデルは3種類用意しました。各モデルは以下のような構造です。

```
Train データセットのクラスごとのデータ数:
クラス "left" のデータ数: 3242サンプル
クラス "right" のデータ数: 97サンプル
クラス "straight" のデータ数: 1068サンプル

Validation データセットのクラスごとのデータ数:
クラス "left" のデータ数: 219サンプル
クラス "right" のデータ数: 8サンプル
クラス "straight" のデータ数: 717サンプル

Test データセットのクラスごとのデータ数:
クラス "left" のデータ数: 370サンプル
クラス "right" のデータ数: 52サンプル
クラス "straight" のデータ数: 245サンプル
```
コース班時計周りにデータを取ったため、右のサンプルが不足しています。
これに対して私は、量子化認識学習モデルと、量子化と不均一ラベルに対する誤分類コストを同時に学ばせる、つまり右であるにもかかわらずまっすぐと誤分類する
場面にコストを置き学習させて比較しました。各モデルは100エポック、オプティマイザーはSGD, lr=0.001, momentum = 0.9, nestrov = True, weigth_decay = 5e-4で学習させます。
より、主張を強固なものとするためモデルは、3つ作りました。
各モデルは、以下のような構造を使います。

![image](https://github.com/user-attachments/assets/41b514cc-c60f-4d1c-a7e0-a1cea2cd2c92)


![image](https://github.com/user-attachments/assets/c6a0d9e7-056e-4917-b811-36f2aae20fd0)


結果
以下が実験結果です。


![image](https://github.com/user-attachments/assets/75dd3d7d-9d65-48c4-900f-cfcbcacc3aa0)

![image](https://github.com/user-attachments/assets/0e087dc6-4f3e-475c-bc67-6cbe89cadf16)

![image](https://github.com/user-attachments/assets/bf2aa78f-2f98-42d1-bb1b-f63adbf9bdcc)

予想に反し、モデル1およびモデル2では、右ラベルが従来の量子化認識学習モデルよりもマジョリティクラス（直進）に分類されやすくなるという結果が得られました。
しかしながら、全体的な精度は従来の量子化認識学習モデルより向上する結果が得られました。

この結果の要因として、以下の2点が考えられます。

Testデータのrightクラスのサンプル数が極端に少なく、マジョリティクラスに分類されやすかったこと

Testデータのrightクラスに、直進ラベルに似た画像が混入していたこと

それでも、全体的な精度向上が確認できたため、モデルIを用いてコース上で右方向からスタートし、各モデルでのコースアウト回数を調べました。

https://github.com/user-attachments/assets/5e9aa4cf-3ac1-4141-ab12-2e034185898d


その結果、学習を改善したモデルは、従来のモデルよりもコースアウト回数が2回分少ないという結果が得られました。
